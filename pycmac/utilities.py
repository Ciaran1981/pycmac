#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ciaran Robb

A module which provides various ancillary functions for processing SfM with Micmac. 


"""
#from shapely.wkt import loads
#from shapely.geometry import Polygon, box, LineString, Point, LinearRing
import numpy as np
import pandas as pd
import os
from subprocess import call
import glob2
import cv2
from joblib import Parallel, delayed
import lxml.etree
import lxml.builder    
from os import path
from shutil import copy, move
import gdal
from tqdm import tqdm
import ogr, osr
from glob2 import glob
from sklearn import metrics
from PIL import Image
import sys
import re
from skimage.feature import (match_descriptors, ORB, plot_matches)
from skimage.color import rgb2gray
from skimage import exposure
import matplotlib.pyplot as plt
import math
from mapboxgl.viz import *
from mapboxgl.utils import df_to_geojson, create_radius_stops, scale_between
from mapboxgl.utils import create_color_stops


def mm3d(folder, cmd, *args, **kwargs):
    
    """
    Execute a micmac command via mm3d just as it would be in the micmac command 
    line - purely for convenience  - you'd be as well using the command line directly
    
    All args kwargs must be in this format where the arg is a string and the kwarg is a bytecode=string

        eg - mm3d(myfolder, 'Malt', 'Ortho', ".*JPG" 'Ground_UTM', DefCor="0", DoOrtho="0")
        
    There will be the odd time where this may not work!
    
    Parameters
    ----------
    folder : string
           working directory
        
    ext : string
                 image extention e.g JPG, tif     
    
    """
    
    os.chdir(folder)
    
    cmd = ["mm3d"]
    
    if args != None:
        for a in args:
            cmd.append(a)
    
    if kwargs != None:
        for k in kwargs.items():
            oot = re.findall(r'\w+',str(k))
            anArg = oot[0]+'='+oot[1]
            cmd.append(anArg)
            
    call(cmd)

def make_csv(folder,  ext="tif"):
    
    """
    make a csv for use with micmac
    
    Parameters
    ----------
    folder : string
           working directory
        
    ext : string
                 image extention e.g JPG, tif     
    
    """
    
    #TODO improve this lazy crap
    os.chdir(folder)
    
    cmd  = ["mm3d", "XifGps2Txt",  ".*"+ext]
    
    ret = call(cmd)

    
    if ret !=0:
        print('A micmac error has occured - check the log file')
        sys.exit()
    txtFile = path.join(folder, "GpsCoordinatesFromExif.txt")
    #stk ex lazyness
    with open(txtFile, 'r+') as f:
        line = "#F=N X Y Z"
        content = f.read()
        f.seek(0, 0)
        f.write(line.rstrip('\r\n') + '\n' + content)
    #Finally
    os.rename(txtFile, path.join(folder, "log.csv"))


def calib_subset(folder, csv, ext="JPG",  algo="Fraser", delim=","):
    
    """
    
    A function for calibrating on an image subset then initialising a global
    orientation 
            
    Notes
    -----------
    
    Eliminates the need to type lenghty file patterns via Micmac and combines 
    
    the subset and main orientation in one function
    
        
    Parameters
    -----------
    
    folder : string
           working directory
    proj : string
           a UTM zone eg "30 +north" 
        
    mode : string
             Correlation mode - Ortho, UrbanMNE, GeomImage
        
    ext : string
                 image extention e.g JPG, tif
    
    orientation : string
                 orientation folder to use (generated by previous tools/cmds)
                 default is "Ground_UTM"
    
       
    """
    
    # Use simple file reading and string manipulation to get what we need
    
    
    os.chdir(folder)
    
    df = pd.read_csv(csv, sep=delim, index_col=False)
    
    imList = list(df['#F=N'])
    
    subStr = str(imList)
    
    sub2 = subStr.replace("[", "")
    sub2 = sub2.replace("]", "")
    sub2 = sub2.replace("'", "") 
    sub2 = sub2.replace(", ", "|")                 
    
    mm3d = ["mm3d", "Tapas", algo, sub2,  "Out=Calib"]
    
    mm3dFinal = ["mm3d", "Tapas", algo, ".*"+ext, "Out=Arbitrary", 
                 "InCal=Calib"]
    
    call(mm3d)
    
    ret = call(mm3d)

    if ret !=0:
        print('A micmac error has occured - check the log file')
        sys.exit()
    
    ret = call(mm3dFinal)
    
    if ret !=0:
        print('A micmac error has occured - check the log file')
        sys.exit()
    
def plot_img_csv(folder, csv='log.csv', delim=" ", dispCol="Z"):
    
    """
    Plot image GPS csv on a map with mapbox
    
    Parameters
    ----------
    folder: string
           working directory
        
    csv: string
         csv name - log.csv is default
    
    delim: string
          delimiter of csv " " (space) is defaut;

    """
    
    df = pd.read_csv(csv, sep=" ", index_col=False)
    
    token = 'pk.eyJ1IjoibWljYXNlbnNlIiwiYSI6ImNqYWx5dWNteTJ3cWYzMnBicmZid3g2YzcifQ.Zrq9t7GYocBtBzYyT3P4sw'
    color_stops = create_color_stops(np.linspace( df[dispCol].min(), 
                                                 df[dispCol].max(),
                                                 num=8), colors='YlOrRd')
    data = df_to_geojson(df, ["#F=N", "Z"],lat='Y',lon='X')
    viz = CircleViz(data, access_token=token, color_property=dispCol,
                    color_stops=color_stops,
                    center=[df['X'].median(),df['Y'].median()], 
                    zoom=16, height='600px',
                    style='mapbox://styles/mapbox/satellite-streets-v9')
    viz.show()
    
def _getExtent(gt,cols,rows):
    ''' Return list of corner coordinates from a geotransform

        @type gt:   C{tuple/list}
        @param gt: geotransform
        @type cols:   C{int}
        @param cols: number of columns in the dataset
        @type rows:   C{int}
        @param rows: number of rows in the dataset
        @rtype:    C{[float,...,float]}
        @return:   coordinates of each corner
    '''
    ext=[]
    xarr=[0,cols]
    yarr=[0,rows]

    for px in xarr:
        for py in yarr:
            x=gt[0]+(px*gt[1])+(py*gt[2])
            y=gt[3]+(px*gt[4])+(py*gt[5])
            ext.append([x,y])
        yarr.reverse()
    return ext

def _reprojectCoords(coords,src_srs,tgt_srs):
    ''' Reproject a list of x,y coordinates.

        @type geom:     C{tuple/list}
        @param geom:    List of [[x,y],...[x,y]] coordinates
        @type src_srs:  C{osr.SpatialReference}
        @param src_srs: OSR SpatialReference object
        @type tgt_srs:  C{osr.SpatialReference}
        @param tgt_srs: OSR SpatialReference object
        @rtype:         C{tuple/list}
        @return:        List of transformed [[x,y],...[x,y]] coordinates
    '''
    trans_coords=[]
    transform = osr.CoordinateTransformation( src_srs, tgt_srs)
    for x,y in coords:
        x,y,z = transform.TransformPoint(x,y)
        trans_coords.append([x,y])
    return trans_coords

def plot_result(folder, inRas, proj=32630):
    
    """
    Plot image GPS csv on a map with mapbox
    
    Parameters
    ----------
    folder: string
           working directory
    
    inRas: string
          name of image in the OUTPUT folder

    """
        
    os.chdir(folder)
    
    pth = os.path.join(folder, "OUTPUT", inRas)
    
    inRas = gdal.Open(pth)
    
    rgt = inRas.GetGeoTransform()
    
    cols = inRas.RasterXSize
    rows = inRas.RasterYSize
    
    ext = _getExtent(rgt,cols,rows)

        
    rf = inRas.GetProjectionRef()
    
    
    sr = osr.SpatialReference()
    
    sr.ImportFromEPSG(proj)
    
    # or 3857 pseudo mercator....
    srs = osr.SpatialReference()
    srs.ImportFromEPSG(4326)
    
    trans_coords = _reprojectCoords(ext, sr, srs)


    token = ('pk.eyJ1IjoibWljYXNlbnNlIiwiYSI6ImNqYWx5dWNteTJ3cWYzMnBicmZid3g2YzcifQ.Zrq9t7GYocBtBzYyT3P4sw')
    
    bands = np.arange(inRas.RasterCount)
    bands+=1
    
    bandList = bands.tolist()
    
    img = raster2array(pth, bands=bandList)
    
    finalIm = np.uint8(exposure.rescale_intensity(img, out_range='uint8'))
    
    del img
    
    viz = ImageViz(finalIm,
               trans_coords, 
               access_token=token,
               height='600px',
               zoom=5)
    viz.show()
    
def convert_c3p(folder, lognm, ext="JPG", mspec=False, delim=','):
    
    """
    Edit csv file for c3p to work with MicMac.
    
    This is intended for the output from the software of a C-Astral drone
    
    This assumes the column order is name, x, y, z
    
    Parameters
    ----------  
    
    folder : string
            path to folder containing jpegs
    lognm : string
            path to c3p derived csv file
    ext : string
            image extension
    delim : string
            the csv delimiter of the input
                           
    """
    # Get a list of file paths 
    fileList = glob2.glob(os.path.join(folder, "*."+ext))
    
    #split them so it is just the img (ugly yes)
    # these will constitute the first column of the output csv

    
    # wow this is getting uglier works well though
    #filesFin = [f[:-6]+'.tif' for f in files if "_1" in f]
   
    
    pdcsv=pd.read_csv(lognm, sep=delim, index_col=False)



    
    files = [os.path.split(file)[1] for file in fileList]
    files.sort()
    
    if mspec == True:
        files = [f[:-6]+'.tif' for f in files if "_1" in f]
        pdcsv = pdcsv[pdcsv['FileName'].str.contains("_1")]
    
    
                                         
                                         
    fleDf= pd.DataFrame(files, columns=["#F=N"])

    newCsv = pd.concat([fleDf["#F=N"], 
                              pdcsv['Longitude'], pdcsv['Latitude'],
                              pdcsv['Altitude']], axis=1)
    
    # header for MicMac     
    hdr = ["#F=N", "X", "Y", "Z"]
         

    # insert new header
    newCsv.columns = [hdr] 
 
        
                
    rgblog = os.path.join(folder,lognm[:-4]+'edited.csv')  
    
    newCsv.to_csv(rgblog, sep=' ', index=False, header=hdr)
        
#def convert_slant(folder, lognm, ext="tif", mspec=False, delim=','):
#    
#    """
#    Edit csv file for slant range log to work with MicMac.
#    
#    This is intended to produce an image/gps index for slantrange log
#    
#    This assumes the column order is name, x, y, z
#    
#    Parameters
#    ----------  
#    
#    folder : string
#            path to folder containing jpegs
#    lognm : string
#            path to c3p derived csv file
#    ext : string
#            image extension
#    delim : string
#            the csv delimiter of the input
#                           
#    """
#    # Get a list of file paths 
#    fileList = glob2.glob(os.path.join(folder, "*."+ext))
#    
#    #split them so it is just the img (ugly yes)
#    # these will constitute the first column of the output csv
#
#    
#    # wow this is getting uglier works well though
#    #filesFin = [f[:-6]+'.tif' for f in files if "_1" in f]
##   
##    
##    pdcsv=pd.read_csv(lognm, sep=delim)
##    
##    For ref ONLY!    
##    header = ['imageCount', ' timestamp', ' global_lat', ' global_lon', ' global_hae',
##       ' roll', ' pitch', ' yaw', ' gps_lat', ' gps_lon', ' fix', ' noise',
##       ' jamming', ' satellites', ' range', ' uins_lat', ' uins_lon',
##       ' uins_hae', ' uins_fix', ' uins_sats', ' uins_cnoMean', ' uins_roll',
##       ' uins_pitch', ' uins_yaw']
#    
#    with open(lognm, 'r') as f:
#        header = f.readline().strip('\n').split(delim)
#        
#        nm = header.index('imageCount')
#        x_col = header.index(' global_lon') 
#        y_col = header.index(' global_lat')
#        z_col = header.index(' global_hae')
#        imList = []
#        x = []
#        y = []
#        z = []
#        
#        for line in f:
#                l = line.strip('\n').split(delim)
#                imList.append(l[nm])
#                x.append(l[x_col])
#                y.append(l[y_col])
#                z.append(l[z_col])
#
#    imList.sort()



    
    files = [os.path.split(file)[1] for file in fileList]
    files.sort()
    
    if mspec == True:
        files = [f[:-6]+'.tif' for f in files if "_1" in f]
        pdcsv = pdcsv[pdcsv['FileName'].str.contains("_1")]
    
    
                                         
                                         
    fleDf= pd.DataFrame(files, columns=["#F=N"])

    newCsv = pd.concat([fleDf["#F=N"], 
                              pdcsv['Longitude'], pdcsv['Latitude'],
                              pdcsv['Altitude']], axis=1)
    
    # header for MicMac     
    hdr = ["#F=N", "X", "Y", "Z"]
         

    # insert new header
    newCsv.columns = [hdr] 
 
        
                
    rgblog = os.path.join(folder,lognm[:-4]+'edited.csv')  
    
    newCsv.to_csv(rgblog, sep=' ', index=False, header=hdr)
        

def mv_subset(csv, inFolder, outfolder, sep=" "):
    
    """
    Move a subset of images based on a MicMac csv file
    
    Micmac csv format is column header #F=N X Y Z with space delimiters
    
    Parameters
    ----------  
    
    folder : string
            path to folder containing jpegs
    lognm : string
            path to c3p derived csv file
    sep : string
            the delimiter of the csv (space is default)
                                  
    """
    
    os.chdir(inFolder)
    
    dF = pd.read_csv(csv, sep=sep, index_col=False)
    
    dfList = list(dF['#F=N'])
    
    Parallel(n_jobs=-1,verbose=5)(delayed(copy)(file, 
            outfolder) for file in dfList)
    
def make_xml(csvFile, folder, sep=" "):
    
    """
    Make an xml  for the rtl system in micmac
    
    Parameters
    ----------  
    
    csvFile : string
             csv file with coords to use
    """
    
    # I detest xml writing!!!!!!!!!!!!!!!
    E = lxml.builder.ElementMaker()
    
    root = E.SystemeCoord
    doc = E.BSC
    f1 = E.TypeCoord
    f2 = E.AuxR
    f3 = E.AuxRUnite
    
    csv = pd.read_csv(csvFile, sep=sep, index_col=False)
                
    x = str(csv.X[0])
    y = str(csv.Y[0])
    z = str(csv.Z[0])
    #csv = pd.read_csv(csvFile, sep=sep)#, delimiter=" ")
#    if len(csv.columns) == 1:
#        csv = pd.read_table(csvFile, delimiter=" ")

    xmlDoc = (root(doc(f1('eTC_RTL'),f2(x),
                   f2(y),
                   f2(z),), 
        doc(f1('eTC_WGS84'),
                       f3('eUniteAngleDegre'))))
    
    et = lxml.etree.ElementTree(xmlDoc)
    ootXml = path.join(folder, 'SysCoRTL.xml')
    et.write(ootXml, pretty_print=True)
    
    
def pims_mask(inShp, folder):
    
    """
    Make an xmlmask from a shapefile for polyg3d for pims/c3dc
    The shapefile MUST be rectilinear
    
    Parameters
    ----------  
    
    inShp : string
             shapefile with coords to use
    """
    
    shp = ogr.Open(inShp)
    lyr = shp.GetLayer()
    feat = lyr.GetFeature(0)
    
    # avoid temptation of shapely gettin meesy these days
    
    geom = feat.GetGeometryRef()
    ring = geom.GetGeometryRef(0)
    numpoints = ring.GetPointCount()
    
    points = []
    
    for p in range(numpoints):
            lon, lat, z = ring.GetPoint(p)
            inStr = str(lon)+"," +str(lat)+","+str(z)
            inStr.replace('"', "")
            points.append(inStr)

# gave up on this
#    el = etree.Element('Polyg3D')
#    it = etree.SubElement(el, 'Item')
#    for i in points:      
#        pt = etree.SubElement(it, 'Pt', text=i)
        
#    md = etree.SubElement(it, 'Mode', text="1")
#
#    
#    subel.text = 'World'
#    # I detest xml writing!!!!!!!!!!!!!!!
    E = lxml.builder.ElementMaker()
#    
    root = E.Polyg3D
    doc = E.Item
    coord = E.Pt
    mode=E.Mode


    xmlDoc = (root(doc(coord(points[0]),
                   coord(points[1]),
                   coord(points[2]),
                   coord(points[3]),
                   mode('1'))))
    
    et = lxml.etree.ElementTree(xmlDoc)
    ootXml = path.join(folder, 'polyg3d.xml')
    et.write(ootXml, pretty_print=True)


def make_sys_utm(folder, proj):
    
    """
    Make an xml  for the geographic system in micmac
    
    Parameters
    ----------  
    
    folder : string
             working directory
    proj : a proj format definition in UTM
            e.g +proj=utm +zone=30 +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
    
    """
    
    E = lxml.builder.ElementMaker()
    
    root = E.SystemeCoord
    doc = E.BSC
    f1 = E.TypeCoord
    f2 = E.AuxR
    f3 = E.AuxStr
    

    xmlDoc = (root(doc(f1('eTC_Proj4'),
                   f2('1'),
                   f2('1'), 
                   f2('1'),
                   f3(proj))))
    et = lxml.etree.ElementTree(xmlDoc)
    
    ootXml = path.join(folder,'SysUTM.xml')
    et.write(ootXml, pretty_print=True)
    

def ori_to_meshlab(folder, imfolder, ext="JPG", ori="Ground_UTM"):
    
    """
    Export to meshlab format to use for texturing
    First copy the images you want to use to a different folder 
    
    Parameters
    ----------  
    
    folder: string
             working directory
    imfolder: string
        a folder containing the selected pics
    ext: string
         the image extension
    ori: string
        the orientation folder
    
    
    """
    
    
    
    os.chdir(folder)
    
    
    
    initList = glob(path.join(imfolder, "*"+ext))
    
    imList = [path.split(i)[1] for i in initList]
    
    subStr = str(imList)
    
    sub2 = subStr.replace("[", "")
    sub2 = sub2.replace("]", "")
    sub2 = sub2.replace("'", "") 
    sub2 = sub2.replace(", ", "|")

    mm3d = ["mm3d", "Apero2Meshlab", sub2, ori, "UnDist=1"]

    ret = call(mm3d)
    
    if ret !=0:
        print('A micmac error has occured - check the log file')
        sys.exit()     

def fill_nodata(inRas, maxSearchDist=5, smoothingIterations=1, 
                bands=[1]):
    
    """
    fill no data using gdal
    
    Parameters
    ----------
    
    inRas: string
              the input image 
            
    maxSearchDist: int
              the input polygon file path 
        
    smoothingIterations: int (optional)
             the clipped raster
             
    maskBand: bool (optional)
             the mask band for where to fill      
    
    """
    
    rds = gdal.Open(inRas, gdal.GA_Update)
    
    #   The nump and gdal dtype (ints)
        #   {"uint8": 1,"int8": 1,"uint16": 2,"int16": 3,"uint32": 4,"int32": 5,
        #    "float32": 6, "float64": 7, "complex64": 10, "complex128": 11}
        
        # a numpy gdal conversion dict - this seems a bit long-winded
#        dtypes = {"1": np.uint8, "2": np.uint16,
#              "3": np.int16, "4": np.uint32,"5": np.int32,
#              "6": np.float32,"7": np.float64,"10": np.complex64,
#              "11": np.complex128}
    
#    if outRas != None:
#        bd = bnd = rds.GetRasterBand(bands[0])
#        _copy_dataset_config(rds, FMT = 'Gtiff', outMap=outRas,
#                         dtype = bd.DataType, bands=rds.RasterCount)
    
    for band in tqdm(bands):
        bnd = rds.GetRasterBand(band)
#        # clumsy change this
#        if outRas !=None: 
        gdal.FillNodata(targetBand=bnd, maskBand=None, 
                         maxSearchDist=maxSearchDist, 
                         smoothingIterations=smoothingIterations)
    
    rds.FlushCache()
    
    rds=None
    
    
def _copy_dataset_config(inDataset, FMT = 'Gtiff', outMap = 'copy',
                          bands = 1, dtype=gdal.GDT_Int32):
    """Copies a dataset without the associated rasters.

    """
    if FMT == 'HFA':
        fmt = '.img'
    if FMT == 'KEA':
        fmt = '.kea'
    if FMT == 'Gtiff':
        fmt = '.tif'
    
    x_pixels = inDataset.RasterXSize  # number of pixels in x
    y_pixels = inDataset.RasterYSize  # number of pixels in y
    geotransform = inDataset.GetGeoTransform()
    PIXEL_SIZE = geotransform[1]  # size of the pixel assuming they are square.
    #if not would need w x h
    x_min = geotransform[0]
    y_max = geotransform[3]
    # x_min & y_max are like the "top left" corner.
    projection = inDataset.GetProjection()
    geotransform = inDataset.GetGeoTransform()   
    #dtype=gdal.GDT_Int32
    driver = gdal.GetDriverByName(FMT)
    
    
    # Set params for output raster
    outDataset = driver.Create(
        outMap, 
        x_pixels,
        y_pixels,
        bands,
        dtype)

    outDataset.SetGeoTransform((
        x_min,    # 0
        PIXEL_SIZE,  # 1
        0,                      # 2
        y_max,    # 3
        0,                      # 4
        -PIXEL_SIZE))
        
    outDataset.SetProjection(projection)
    
    return outDataset

def mask_raster_multi(inputIm,  mval=1, outval = None, mask=None,
                    blocksize = 256, FMT = None, dtype=None):
    """ 
    Perform a numpy masking operation on a raster where all values
    corresponding to  mask value are retained - does this in blocks for
    efficiency on larger rasters
    
    Parameters 
    ----------- 
    
    inputIm : string
              the input raster 
        
    mval : int
           the masking value that delineates pixels to be kept
        
    outval : numerical dtype eg int, float
              the areas removed will be written to this value default is 0
        
    mask : string
            the mask raster to be used (optional)
        
    FMT : string
          the output gdal format eg 'Gtiff', 'KEA', 'HFA'
        
        
    blocksize : int
                the chunk of raster read in & write out

    """

    if FMT == None:
        FMT = 'Gtiff'
        fmt = '.tif'
    if FMT == 'HFA':
        fmt = '.img'
    if FMT == 'KEA':
        fmt = '.kea'
    if FMT == 'Gtiff':
        fmt = '.tif'
    
    
    if outval == None:
        outval = 0
    
    inDataset = gdal.Open(inputIm, gdal.GA_Update)
    bands = inDataset.RasterCount
    
    bnnd = inDataset.GetRasterBand(1)
    cols = inDataset.RasterXSize
    rows = inDataset.RasterYSize

    
    
    # So with most datasets blocksize is a row scanline, but 256 always seems 
    # quickest - hence it is specified above as default
    if blocksize == None:
        blocksize = bnnd.GetBlockSize()
        blocksizeX = blocksize[0]
        blocksizeY = blocksize[1]
    else:
        blocksizeX = blocksize
        blocksizeY = blocksize
    
    if mask != None:
        msk = gdal.Open(mask)
        maskRas = msk.GetRasterBand(1)
        
        for i in tqdm(range(0, rows, blocksizeY)):
            if i + blocksizeY < rows:
                numRows = blocksizeY
            else:
                numRows = rows -i
        
            for j in range(0, cols, blocksizeX):
                if j + blocksizeX < cols:
                    numCols = blocksizeX
                else:
                    numCols = cols - j
                mask = maskRas.ReadAsArray(j, i, numCols, numRows)
                if mval not in mask:
                    array = np.zeros(shape=(numRows,numCols))
                    for band in range(1, bands+1):
                        bnd = inDataset.GetRasterBand(band)
                        array = bnd.ReadAsArray(j, i, numCols, numRows)
                        array[mask != mval]=0
                        array[array < 0]=0
                        bnd.WriteArray(array, j, i)
                else:
                    
                    for band in range(1, bands+1):
                        bnd = inDataset.GetRasterBand(band)
                        array = bnd.ReadAsArray(j, i, numCols, numRows)
                        array[mask != mval]=0
                        array[array < 0]=0
                        bnd.WriteArray(array, j, i)
                        
    else:
             
        for i in tqdm(range(0, rows, blocksizeY)):
                if i + blocksizeY < rows:
                    numRows = blocksizeY
                else:
                    numRows = rows -i
            
                for j in range(0, cols, blocksizeX):
                    if j + blocksizeX < cols:
                        numCols = blocksizeX
                    else:
                        numCols = cols - j
                    for band in range(1, bands+1):
                        bnd = inDataset.GetRasterBand(1)
                        array = bnd.ReadAsArray(j, i, numCols, numRows)
                        array[array != mval]=0
                        if outval != None:
                            array[array == mval] = outval     
                            bnd.WriteArray(array, j, i)

        inDataset.GetRasterBand(1).SetNoDataValue(0)
           
        inDataset.FlushCache()
        inDataset = None

def _varlap(image):
    
    #variance_of_laplacian

	return cv2.Laplacian(image, cv2.CV_64F).var()

def detect_blur(inFolder, ext="JPG", threshold=100):
    
    """ 
    Detect if images are blurry then move them to a blur folder prior to SfM
    
    using a laplacian convolution.....
    
    
    Parameters 
    ----------- 
    
    inFolder: string
              the input folder with images

    ext: string
                 image extention e.g JPG, tif
    threshold: int
                the threshold of blurryness to remove photo 
                around 100 usually does it

                 
    """
    
    imList = glob(os.path.join(inFolder, "*."+ext))
    if os.path.exists(os.path.join(inFolder, "blur")):
        pass
    else:
        os.mkdir(os.path.join(inFolder, "blur"))
    for imagePath in imList:
        image = cv2.imread(imagePath)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        score = _varlap(gray)

        if score > threshold:
            continue
        else:
            _, tl = os.path.split(imagePath)
            outPath = os.path.join(inFolder, "blur", tl)
            move(imagePath, outPath)
            
def get_vid(video, outFolder, ext="JPG", cam="Iphone_SE", foc="2.4", foc35="29"):
    
    """ 
    Extract the frames from a video with the view to using them for SfM
    
    The camera focal length and 35mm equiv must be known as the frames will not contain them
    
    If you have taken a pic with the same platform use exiftool to obtain the info you need
    
    
    Parameters 
    ----------- 
    
    video : string
              the input raster 
        
    outFolder : string
           the masking value that delineates pixels to be kept
        
    num : int 
              the subdivision - e.g. every fifth image

    ext : string
                 image extention e.g JPG, tif
    cam : string
                 the camera focal length as it is required
        
    cam : string
                 the camera focal length as it is required
                 
    """
    
    # stack theft.....
    vidcap = cv2.VideoCapture(video)
    success,image = vidcap.read()
    count = 0
    
    while success:
      cv2.imwrite(path.join(outFolder,"frame%d."+ext) % count, image)     # save frame as JPEG file      
      success,image = vidcap.read()
      print('Read a new frame: ', success)
      count += 1
    os.chdir(outFolder)
    cmd = ["mm3d", "SetExif", "F35="+foc35, "F="+foc, "Cam="+cam]
    
    ret = call(cmd)
    
    if ret !=0:
        print('A micmac error has occured - check the micmac error log')
        sys.exit()
    
      
def num_subset(inFolder, outFolder, num=5, ext="JPG"):
    
    """ 
    Pick a subset of images from a video such as every fifth image (frame)
    
    This assumes you have used ffmpeg or a similar application to extract the frames first
    
    
    Parameters 
    ----------- 
    
    inFolder : string
              the folder with the images in 
        
    outFolder : string
           the folder the output images will go
        
    num : int 
              the subdivision - e.g. every fifth image

    ext : string
                 image extention e.g JPG, tif
        

    """
    # ffmpeg cmd just in case I end up[ doing anything like this]
    # ffmpeg -i *.mp4 Im_0000_%5d_Ok.png
    
    fileList = glob2.glob(os.path.join(inFolder, "*."+ext))
        
    
    
#    files = [os.path.split(file)[1] for file in fileList]
#    files.sort()
    
    ootList = []
    
    for f in range(0, len(fileList), num):
        ootList.append(fileList[f])
        
        
    
    Parallel(n_jobs=-1,verbose=5)(delayed(copy)(fl, 
            outFolder) for fl in ootList)


def rmse_vector_lyr(inShape, attributes):

    """ 
    Using sklearn get the rmse of 2 vector attributes 
    (the actual and predicted of course in the order ['actual', 'pred'])
    
    
    Parameters 
    ----------- 
    
    inShape : string
              the input vector of OGR type
        
    attributes : list
           a list of strings denoting the attributes
         

    """    
    
    #open the layer etc
    shp = ogr.Open(inShape)
    lyr = shp.GetLayer()
    labels = np.arange(lyr.GetFeatureCount())
    
    # empty arrays for att
    pred = np.zeros((1, lyr.GetFeatureCount()))
    true = np.zeros((1, lyr.GetFeatureCount()))
    
    for label in labels: 
        feat = lyr.GetFeature(label)
        true[:,label] = feat.GetField(attributes[0])
        pred[:,label] = feat.GetField(attributes[1])
    
    
    
    error = np.sqrt(metrics.mean_squared_error(true, pred))
    
    return error
    
        
def hist_match(inputImage, templateImage):
    
    
    
    # TODO optimise with either cython or numba
    
    """
    Adjust the pixel values of an image such that its histogram
    matches that of a target image. 
    
    Writes to the inputImage dataset so that it matches
    
    Notes: 
    -----------
        
    As the entire band histogram is required this can become memory
    intensive with very big images
    
    Inspire by/adapted from something on stack on image processing - credit to
    that author

    Parameters
    -----------
    
    inputImage : string
                 image to transform; the histogram is computed over the flattened array
            
    templateImage : string
                    template image can have different dimensions to source    
    
    """
    # TODO - cythinis or numba this one
    
    imgSource = Image.open(inputImage)
    
    sArr = np.array(imgSource)
        
    imgTemp = Image.open(templateImage)
    
    tArr = np.array(imgTemp)
    
    # "sArr" is a height x width x 3 numpy array

    
    #outArrs = []
    
    for band in tqdm(range(0, 3)):
        #print(band)
        # seems to be issue with combining properties as with templateRas hence
        # separate lines
        source = np.asarray(sArr[:,:, band])
        
        oldshape = source.shape
        
        template = np.asarray(tArr[:,:, band])
        
        
        #source = source.ravel()
        #template = template.ravel()
                
        
        # get the set of unique pixel values and their corresponding indices and
        # counts
        s_values, bin_idx, s_counts = np.unique(source.ravel(), return_inverse=True,
                                                return_counts=True)
        t_values, t_counts = np.unique(template.ravel(), return_counts=True)
    
        # take the cumsum of the counts and normalize by the number of pixels to
        # get the empirical cumulative distribution functions for the source and
        # template images (maps pixel value --> quantile)
        s_quantiles = np.cumsum(s_counts).astype(np.float64)
        s_quantiles /= s_quantiles[-1]
        t_quantiles = np.cumsum(t_counts).astype(np.float64)
        t_quantiles /= t_quantiles[-1]
    
        # interpolate linearly to find the pixel values in the template image
        # that correspond most closely to the quantiles in the source image
        interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)
    
        out_array = interp_t_values[bin_idx].reshape(oldshape)
        
        # reuse the var from earlier
        sArr[:,:, band] = out_array
        
    # This seems rather ugly - but going on the docs   
    imOut = Image.fromarray(np.uint8(sArr))
    
    imOut.save(inputImage)

    
def array2raster(array, bands, inRaster, outRas, dtype, FMT=None):
    
    """
    Save a raster from a numpy array using the geoinfo from another.
    
    Parameters
    ----------      
    array : np array
            a numpy array.
    
    bands : int
            the no of bands. 
    
    inRaster : string
               the path of a raster.
    
    outRas : string
             the path of the output raster.
    
    dtype : int 
            though you need to know what the number represents!
            a GDAL datatype (see the GDAL website) e.g gdal.GDT_Int32
    
    FMT  : string 
           (optional) a GDAL raster format (see the GDAL website) eg Gtiff, HFA, KEA.
        
    
    """

    if FMT == None:
        FMT = 'Gtiff'
        
    if FMT == 'HFA':
        fmt = '.img'
    if FMT == 'KEA':
        fmt = '.kea'
    if FMT == 'Gtiff':
        fmt = '.tif'    
    
    inras = gdal.Open(inRaster, gdal.GA_ReadOnly)    
    
    x_pixels = inras.RasterXSize  # number of pixels in x
    y_pixels = inras.RasterYSize  # number of pixels in y
    geotransform = inras.GetGeoTransform()
    PIXEL_SIZE = geotransform[1]  # size of the pixel...they are square so thats ok.
    #if not would need w x h
    x_min = geotransform[0]
    y_max = geotransform[3]
    # x_min & y_max are like the "top left" corner.
    projection = inras.GetProjection()
    geotransform = inras.GetGeoTransform()   

    driver = gdal.GetDriverByName(FMT)

    dataset = driver.Create(
        outRas, 
        x_pixels,
        y_pixels,
        bands,
        dtype)

    dataset.SetGeoTransform((
        x_min,    # 0
        PIXEL_SIZE,  # 1
        0,                      # 2
        y_max,    # 3
        0,                      # 4
        -PIXEL_SIZE))    

    dataset.SetProjection(projection)
    if bands == 1:
        dataset.GetRasterBand(1).WriteArray(array)
        dataset.FlushCache()  # Write to disk.
        dataset=None
        #print('Raster written to disk')
    else:
    # Here we loop through bands
        for band in range(1,bands+1):
            Arr = array[:,:,band-1]
            dataset.GetRasterBand(band).WriteArray(Arr)
        dataset.FlushCache()  # Write to disk.
        dataset=None
        #print('Raster w
        
def raster2array(inRas, bands=[1]):
    
    """
    Read a raster and return an array, either single or multiband

    
    Parameters
    ----------
    
    inRas: string
                  input  raster 
                  
    bands: list
                  a list of bands to return in the array
    
    """
    rds = gdal.Open(inRas)
   
   
    if len(bands) ==1:
        # then we needn't bother with all the crap below
        inArray = rds.GetRasterBand(bands[0]).ReadAsArray()
        
    else:
        #   The nump and gdal dtype (ints)
        #   {"uint8": 1,"int8": 1,"uint16": 2,"int16": 3,"uint32": 4,"int32": 5,
        #    "float32": 6, "float64": 7, "complex64": 10, "complex128": 11}
        
        # a numpy gdal conversion dict - this seems a bit long-winded
        dtypes = {"1": np.uint8, "2": np.uint16,
              "3": np.int16, "4": np.uint32,"5": np.int32,
              "6": np.float32,"7": np.float64,"10": np.complex64,
              "11": np.complex128}
        rdsDtype = rds.GetRasterBand(1).DataType
        inDt = dtypes[str(rdsDtype)]
        
        inArray = np.zeros((rds.RasterYSize, rds.RasterXSize, len(bands)), dtype=inDt) 
        for idx, band in enumerate(bands):  
            rA = rds.GetRasterBand(band).ReadAsArray()
            inArray[:, :, idx]=rA
   
   
    return inArray


def orbplot(folder, imgs):
    
    """
    Plot matching features across 3 images using ORB
    The images MUST overlap
    
    Parameters
    ----------      
    folder: string
            the working directory with images in
    imgs: list of strings
           the images to plot feature matches in the format
           ['img1', 'img2', 'img3']
    
    """
    os.chdir(folder)

    img1 = raster2array(imgs[0], bands=[1,2,3])
    
    img2 = raster2array(imgs[1], bands=[1,2,3])
    
    img3 = raster2array(imgs[2], bands=[1,2,3])
    
    img1 = rgb2gray(img1)
    img2 = rgb2gray(img2)
    img3 = rgb2gray(img3)
    #tform = transform.AffineTransform(scale=(1.3, 1.1), rotation=0.5,
    #                                  translation=(0, -200))
    #img3 = transform.warp(img1, tform)
    
    descriptor_extractor = ORB(n_keypoints=200)
    
    descriptor_extractor.detect_and_extract(img1)
    keypoints1 = descriptor_extractor.keypoints
    descriptors1 = descriptor_extractor.descriptors
    
    descriptor_extractor.detect_and_extract(img2)
    keypoints2 = descriptor_extractor.keypoints
    descriptors2 = descriptor_extractor.descriptors
    
    descriptor_extractor.detect_and_extract(img3)
    keypoints3 = descriptor_extractor.keypoints
    descriptors3 = descriptor_extractor.descriptors
    
    matches12 = match_descriptors(descriptors1, descriptors2, cross_check=True)
    matches13 = match_descriptors(descriptors1, descriptors3, cross_check=True)
    
    fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(30,30))
    
    plt.gray()
    
    plot_matches(ax[0], img1, img2, keypoints1, keypoints2, matches12)
    ax[0].axis('off')
    ax[0].set_title(imgs[0]+" & "+imgs[1]+" feature matches", fontsize=30)
    
    plot_matches(ax[1], img1, img3, keypoints1, keypoints3, matches13)
    ax[1].axis('off')
    ax[1].set_title(imgs[1]+" & "+imgs[2]+" feature matches", fontsize=30)
    
    
    plt.show()
       
