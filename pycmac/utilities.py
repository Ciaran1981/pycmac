#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ciaran Robb

A module which provides various ancillary functions for processing SfM with Micmac. 

https://github.com/Ciaran1981/Sfm/pycmac/
"""
from shapely.wkt import loads
#from shapely.geometry import Polygon, box, LineString, Point, LinearRing
import numpy as np
import pandas as pd
import os
from subprocess import call
import glob2
import cv2
from joblib import Parallel, delayed
import lxml.etree
import lxml.builder    
from os import path
from shutil import copy, move
from subprocess import call
import gdal
from tqdm import tqdm
import ogr
from glob2 import glob
from sklearn import metrics
from PIL import Image
import sys
import re

def mm3d(folder, cmd, *args, **kwargs):
    
    """
    Execute a micmac command via mm3d just as it would be in the micmac command 
    line - purely for convenience  - you'd be as well using the command line directly
    
    All args kwargs must be in this format where the arg is a string and the kwarg is a bytecode=string

        eg - mm3d(myfolder, 'Malt', 'Ortho', ".*JPG" 'Ground_UTM', DefCor="0", DoOrtho="0")
        
    There will be the odd time where this may not work!
    
    Parameters
    ----------
    folder : string
           working directory
        
    ext : string
                 image extention e.g JPG, tif     
    
    """
    
    os.chdir(folder)
    
    cmd = ["mm3d"]
    
    if args != None:
        for a in args:
            cmd.append(a)
    
    if kwargs != None:
        for k in kwargs.items():
            oot = re.findall(r'\w+',str(k))
            anArg = oot[0]+'='+oot[1]
            cmd.append(anArg)
            
    call(cmd)

def make_csv(folder,  ext="tif"):
    
    """
    make a csv for use with micmac
    
    Parameters
    ----------
    folder : string
           working directory
        
    ext : string
                 image extention e.g JPG, tif     
    
    """
    
    #TODO improve this lazy crap
    os.chdir(folder)
    
    cmd  = ["mm3d", "XifGps2Txt",  ".*"+ext]
    
    ret = call(cmd)

    
    if ret !=0:
        print('A micmac error has occured - check the log file')
        sys.exit()
    txtFile = path.join(folder, "GpsCoordinatesFromExif.txt")
    #stk ex lazyness
    with open(txtFile, 'r+') as f:
        line = "#F=N X Y Z"
        content = f.read()
        f.seek(0, 0)
        f.write(line.rstrip('\r\n') + '\n' + content)
    #Finally
    os.rename(txtFile, path.join(folder, "log.csv"))

def calib_subset(folder, csv, ext="JPG",  algo="Fraser", delim=","):
    
    """
    
    A function for calibrating on an image subset then initialising a global
    orientation 
            
    Notes
    -----------
    
    Eliminates the need to type lenghty file patterns via Micmac and combines 
    
    the subset and main orientation in one function
    
        
    Parameters
    -----------
    
    folder : string
           working directory
    proj : string
           a UTM zone eg "30 +north" 
        
    mode : string
             Correlation mode - Ortho, UrbanMNE, GeomImage
        
    ext : string
                 image extention e.g JPG, tif
    
    orientation : string
                 orientation folder to use (generated by previous tools/cmds)
                 default is "Ground_UTM"
    
       
    """
    
    # Use simple file reading and string manipulation to get what we need
    
    
    os.chdir(folder)
    
    with open(csv, 'r') as f:
        header = f.readline().strip('\n').split(delim)
        nm = header.index("#F=N")
        x_col = header.index('X') 
        y_col = header.index('Y')
        z_col = header.index('Z')
        imList = []
        x = []
        y = []
        z = []
        
        for line in f:
                l = line.strip('\n').split(delim)
                imList.append(l[nm])
                x.append(l[x_col])
                y.append(l[y_col])
                z.append(l[z_col])

    imList.sort()
    
    
    #subList = [path.split(item)[1] for item in imList]
    
    subStr = str(imList)
    
    sub2 = subStr.replace("[", "")
    sub2 = sub2.replace("]", "")
    sub2 = sub2.replace("'", "") 
    sub2 = sub2.replace(", ", "|")                 
    
    mm3d = ["mm3d", "Tapas", algo, sub2,  "Out=Calib"]
    
    mm3dFinal = ["mm3d", "Tapas", algo, ".*"+ext, "Out=Arbitrary", 
                 "InCal=Calib"]
    
    call(mm3d)
    
    call(mm3dFinal)
    
def convert_c3p(folder, lognm, ext="JPG", mspec=False, delim=','):
    
    """
    Edit csv file for c3p to work with MicMac.
    
    This is intended for the output from the software of a C-Astral drone
    
    This assumes the column order is name, x, y, z
    
    Parameters
    ----------  
    
    folder : string
            path to folder containing jpegs
    lognm : string
            path to c3p derived csv file
    ext : string
            image extension
    delim : string
            the csv delimiter of the input
                           
    """
    # Get a list of file paths 
    fileList = glob2.glob(os.path.join(folder, "*."+ext))
    
    #split them so it is just the img (ugly yes)
    # these will constitute the first column of the output csv

    
    # wow this is getting uglier works well though
    #filesFin = [f[:-6]+'.tif' for f in files if "_1" in f]
   
    
    pdcsv=pd.read_csv(lognm, sep=delim)



    
    files = [os.path.split(file)[1] for file in fileList]
    files.sort()
    
    if mspec == True:
        files = [f[:-6]+'.tif' for f in files if "_1" in f]
        pdcsv = pdcsv[pdcsv['FileName'].str.contains("_1")]
    
    
                                         
                                         
    fleDf= pd.DataFrame(files, columns=["#F=N"])

    newCsv = pd.concat([fleDf["#F=N"], 
                              pdcsv['Longitude'], pdcsv['Latitude'],
                              pdcsv['Altitude']], axis=1)
    
    # header for MicMac     
    hdr = ["#F=N", "X", "Y", "Z"]
         

    # insert new header
    newCsv.columns = [hdr] 
 
        
                
    rgblog = os.path.join(folder,lognm[:-4]+'edited.csv')  
    
    newCsv.to_csv(rgblog, sep=' ', index=False, header=hdr)
        
#def convert_slant(folder, lognm, ext="tif", mspec=False, delim=','):
#    
#    """
#    Edit csv file for slant range log to work with MicMac.
#    
#    This is intended to produce an image/gps index for slantrange log
#    
#    This assumes the column order is name, x, y, z
#    
#    Parameters
#    ----------  
#    
#    folder : string
#            path to folder containing jpegs
#    lognm : string
#            path to c3p derived csv file
#    ext : string
#            image extension
#    delim : string
#            the csv delimiter of the input
#                           
#    """
#    # Get a list of file paths 
#    fileList = glob2.glob(os.path.join(folder, "*."+ext))
#    
#    #split them so it is just the img (ugly yes)
#    # these will constitute the first column of the output csv
#
#    
#    # wow this is getting uglier works well though
#    #filesFin = [f[:-6]+'.tif' for f in files if "_1" in f]
##   
##    
##    pdcsv=pd.read_csv(lognm, sep=delim)
##    
##    For ref ONLY!    
##    header = ['imageCount', ' timestamp', ' global_lat', ' global_lon', ' global_hae',
##       ' roll', ' pitch', ' yaw', ' gps_lat', ' gps_lon', ' fix', ' noise',
##       ' jamming', ' satellites', ' range', ' uins_lat', ' uins_lon',
##       ' uins_hae', ' uins_fix', ' uins_sats', ' uins_cnoMean', ' uins_roll',
##       ' uins_pitch', ' uins_yaw']
#    
#    with open(lognm, 'r') as f:
#        header = f.readline().strip('\n').split(delim)
#        
#        nm = header.index('imageCount')
#        x_col = header.index(' global_lon') 
#        y_col = header.index(' global_lat')
#        z_col = header.index(' global_hae')
#        imList = []
#        x = []
#        y = []
#        z = []
#        
#        for line in f:
#                l = line.strip('\n').split(delim)
#                imList.append(l[nm])
#                x.append(l[x_col])
#                y.append(l[y_col])
#                z.append(l[z_col])
#
#    imList.sort()



    
    files = [os.path.split(file)[1] for file in fileList]
    files.sort()
    
    if mspec == True:
        files = [f[:-6]+'.tif' for f in files if "_1" in f]
        pdcsv = pdcsv[pdcsv['FileName'].str.contains("_1")]
    
    
                                         
                                         
    fleDf= pd.DataFrame(files, columns=["#F=N"])

    newCsv = pd.concat([fleDf["#F=N"], 
                              pdcsv['Longitude'], pdcsv['Latitude'],
                              pdcsv['Altitude']], axis=1)
    
    # header for MicMac     
    hdr = ["#F=N", "X", "Y", "Z"]
         

    # insert new header
    newCsv.columns = [hdr] 
 
        
                
    rgblog = os.path.join(folder,lognm[:-4]+'edited.csv')  
    
    newCsv.to_csv(rgblog, sep=' ', index=False, header=hdr)
        

def mv_subset(csv, inFolder, outfolder, sep=" "):
    
    """
    Move a subset of images based on a MicMac csv file
    
    Micmac csv format is column header #F=N X Y Z with space delimiters
    
    Parameters
    ----------  
    
    folder : string
            path to folder containing jpegs
    lognm : string
            path to c3p derived csv file
    sep : string
            the delimiter of the csv (space is default)
                                  
    """
    
    os.chdir(inFolder)
    
    dF = pd.read_csv(csv, sep=sep)
    
    dfList = list(dF['#F=N'])
    
    Parallel(n_jobs=-1,verbose=5)(delayed(copy)(file, 
            outfolder) for file in dfList)
    
def make_xml(csvFile, folder, sep=" "):
    
    """
    Make an xml  for the rtl system in micmac
    
    Parameters
    ----------  
    
    csvFile : string
             csv file with coords to use
    """
    
    # I detest xml writing!!!!!!!!!!!!!!!
    E = lxml.builder.ElementMaker()
    
    root = E.SystemeCoord
    doc = E.BSC
    f1 = E.TypeCoord
    f2 = E.AuxR
    f3 = E.AuxRUnite
    
    csv = pd.read_csv(csvFile, sep=sep)
                
    x = str(csv.X[0])
    y = str(csv.Y[0])
    z = str(csv.Z[0])
    #csv = pd.read_csv(csvFile, sep=sep)#, delimiter=" ")
#    if len(csv.columns) == 1:
#        csv = pd.read_table(csvFile, delimiter=" ")

    xmlDoc = (root(doc(f1('eTC_RTL'),f2(x),
                   f2(y),
                   f2(z),), 
        doc(f1('eTC_WGS84'),
                       f3('eUniteAngleDegre'))))
    
    et = lxml.etree.ElementTree(xmlDoc)
    ootXml = path.join(folder, 'SysCoRTL.xml')
    et.write(ootXml, pretty_print=True)
    
    
def pims_mask(inShp, folder):
    
    """
    Make an xmlmask from a shapefile for polyg3d for pims/c3dc
    The shapefile MUST be rectilinear
    
    Parameters
    ----------  
    
    inShp : string
             shapefile with coords to use
    """
    
    shp = ogr.Open(inShp)
    lyr = shp.GetLayer()
    feat = lyr.GetFeature(0)
    
    # avoid temptation of shapely gettin meesy these days
    
    geom = feat.GetGeometryRef()
    ring = geom.GetGeometryRef(0)
    numpoints = ring.GetPointCount()
    
    points = []
    
    for p in range(numpoints):
            lon, lat, z = ring.GetPoint(p)
            inStr = str(lon)+"," +str(lat)+","+str(z)
            inStr.replace('"', "")
            points.append(inStr)

# gave up on this
#    el = etree.Element('Polyg3D')
#    it = etree.SubElement(el, 'Item')
#    for i in points:      
#        pt = etree.SubElement(it, 'Pt', text=i)
        
#    md = etree.SubElement(it, 'Mode', text="1")
#
#    
#    subel.text = 'World'
#    # I detest xml writing!!!!!!!!!!!!!!!
    E = lxml.builder.ElementMaker()
#    
    root = E.Polyg3D
    doc = E.Item
    coord = E.Pt
    mode=E.Mode


    xmlDoc = (root(doc(coord(points[0]),
                   coord(points[1]),
                   coord(points[2]),
                   coord(points[3]),
                   mode('1'))))
    
    et = lxml.etree.ElementTree(xmlDoc)
    ootXml = path.join(folder, 'polyg3d.xml')
    et.write(ootXml, pretty_print=True)


def make_sys_utm(folder, proj):
    
    """
    Make an xml  for the geographic system in micmac
    
    Parameters
    ----------  
    
    folder : string
             working directory
    proj : a proj format definition in UTM
            e.g +proj=utm +zone=30 +north +ellps=WGS84 +datum=WGS84 +units=m +no_defs"
    
    """
    
    E = lxml.builder.ElementMaker()
    
    root = E.SystemeCoord
    doc = E.BSC
    f1 = E.TypeCoord
    f2 = E.AuxR
    f3 = E.AuxStr
    

    xmlDoc = (root(doc(f1('eTC_Proj4'),
                   f2('1'),
                   f2('1'), 
                   f2('1'),
                   f3(proj))))
    et = lxml.etree.ElementTree(xmlDoc)
    
    ootXml = path.join(folder,'SysUTM.xml')
    et.write(ootXml, pretty_print=True)
    
    
def _copy_dataset_config(inDataset, FMT = 'Gtiff', outMap = 'copy',
                          bands = 1, dtype=gdal.GDT_Int32):
    """Copies a dataset without the associated rasters.

    """
    if FMT == 'HFA':
        fmt = '.img'
    if FMT == 'KEA':
        fmt = '.kea'
    if FMT == 'Gtiff':
        fmt = '.tif'
    
    x_pixels = inDataset.RasterXSize  # number of pixels in x
    y_pixels = inDataset.RasterYSize  # number of pixels in y
    geotransform = inDataset.GetGeoTransform()
    PIXEL_SIZE = geotransform[1]  # size of the pixel assuming they are square.
    #if not would need w x h
    x_min = geotransform[0]
    y_max = geotransform[3]
    # x_min & y_max are like the "top left" corner.
    projection = inDataset.GetProjection()
    geotransform = inDataset.GetGeoTransform()   
    #dtype=gdal.GDT_Int32
    driver = gdal.GetDriverByName(FMT)
    
    
    # Set params for output raster
    outDataset = driver.Create(
        outMap, 
        x_pixels,
        y_pixels,
        bands,
        dtype)

    outDataset.SetGeoTransform((
        x_min,    # 0
        PIXEL_SIZE,  # 1
        0,                      # 2
        y_max,    # 3
        0,                      # 4
        -PIXEL_SIZE))
        
    outDataset.SetProjection(projection)
    
    return outDataset

def mask_raster_multi(inputIm,  mval=1, outval = None, mask=None,
                    blocksize = 256, FMT = None, dtype=None):
    """ 
    Perform a numpy masking operation on a raster where all values
    corresponding to  mask value are retained - does this in blocks for
    efficiency on larger rasters
    
    Parameters 
    ----------- 
    
    inputIm : string
              the input raster 
        
    mval : int
           the masking value that delineates pixels to be kept
        
    outval : numerical dtype eg int, float
              the areas removed will be written to this value default is 0
        
    mask : string
            the mask raster to be used (optional)
        
    FMT : string
          the output gdal format eg 'Gtiff', 'KEA', 'HFA'
        
        
    blocksize : int
                the chunk of raster read in & write out

    """

    if FMT == None:
        FMT = 'Gtiff'
        fmt = '.tif'
    if FMT == 'HFA':
        fmt = '.img'
    if FMT == 'KEA':
        fmt = '.kea'
    if FMT == 'Gtiff':
        fmt = '.tif'
    
    
    if outval == None:
        outval = 0
    
    inDataset = gdal.Open(inputIm, gdal.GA_Update)
    bands = inDataset.RasterCount
    
    bnnd = inDataset.GetRasterBand(1)
    cols = inDataset.RasterXSize
    rows = inDataset.RasterYSize

    
    
    # So with most datasets blocksize is a row scanline, but 256 always seems 
    # quickest - hence it is specified above as default
    if blocksize == None:
        blocksize = bnnd.GetBlockSize()
        blocksizeX = blocksize[0]
        blocksizeY = blocksize[1]
    else:
        blocksizeX = blocksize
        blocksizeY = blocksize
    
    if mask != None:
        msk = gdal.Open(mask)
        maskRas = msk.GetRasterBand(1)
        
        for i in tqdm(range(0, rows, blocksizeY)):
            if i + blocksizeY < rows:
                numRows = blocksizeY
            else:
                numRows = rows -i
        
            for j in range(0, cols, blocksizeX):
                if j + blocksizeX < cols:
                    numCols = blocksizeX
                else:
                    numCols = cols - j
                mask = maskRas.ReadAsArray(j, i, numCols, numRows)
                if mval not in mask:
                    array = np.zeros(shape=(numRows,numCols))
                    for band in range(1, bands+1):
                        bnd = inDataset.GetRasterBand(band)
                        array = bnd.ReadAsArray(j, i, numCols, numRows)
                        array[mask != mval]=0
                        array[array < 0]=0
                        bnd.WriteArray(array, j, i)
                else:
                    
                    for band in range(1, bands+1):
                        bnd = inDataset.GetRasterBand(band)
                        array = bnd.ReadAsArray(j, i, numCols, numRows)
                        array[mask != mval]=0
                        array[array < 0]=0
                        bnd.WriteArray(array, j, i)
                        
    else:
             
        for i in tqdm(range(0, rows, blocksizeY)):
                if i + blocksizeY < rows:
                    numRows = blocksizeY
                else:
                    numRows = rows -i
            
                for j in range(0, cols, blocksizeX):
                    if j + blocksizeX < cols:
                        numCols = blocksizeX
                    else:
                        numCols = cols - j
                    for band in range(1, bands+1):
                        bnd = inDataset.GetRasterBand(1)
                        array = bnd.ReadAsArray(j, i, numCols, numRows)
                        array[array != mval]=0
                        if outval != None:
                            array[array == mval] = outval     
                            bnd.WriteArray(array, j, i)

        inDataset.GetRasterBand(1).SetNoDataValue(0)
           
        inDataset.FlushCache()
        inDataset = None

def _varlap(image):
    
    #variance_of_laplacian

	return cv2.Laplacian(image, cv2.CV_64F).var()

def detect_blur(inFolder, ext="JPG", threshold=100):
    
    """ 
    Detect if images are blurry then move them to a blur folder prior to SfM
    
    using a laplacian convolution.....
    
    
    Parameters 
    ----------- 
    
    inFolder: string
              the input folder with images

    ext: string
                 image extention e.g JPG, tif
    threshold: int
                the threshold of blurryness to remove photo 
                around 100 usually does it

                 
    """
    
    imList = glob(os.path.join(inFolder, "*."+ext))
    if os.path.exists(os.path.join(inFolder, "blur")):
        pass
    else:
        os.mkdir(os.path.join(inFolder, "blur"))
    for imagePath in imList:
        image = cv2.imread(imagePath)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        score = _varlap(gray)

        if score > threshold:
            continue
        else:
            _, tl = os.path.split(imagePath)
            outPath = os.path.join(inFolder, "blur", tl)
            move(imagePath, outPath)
            
def get_vid(video, outFolder, ext="JPG", cam="Iphone_SE", foc="2.4", foc35="29"):
    
    """ 
    Extract the frames from a video with the view to using them for SfM
    
    The camera focal length and 35mm equiv must be known as the frames will not contain them
    
    If you have taken a pic with the same platform use exiftool to obtain the info you need
    
    
    Parameters 
    ----------- 
    
    video : string
              the input raster 
        
    outFolder : string
           the masking value that delineates pixels to be kept
        
    num : int 
              the subdivision - e.g. every fifth image

    ext : string
                 image extention e.g JPG, tif
    cam : string
                 the camera focal length as it is required
        
    cam : string
                 the camera focal length as it is required
                 
    """
    
    # stack theft.....
    vidcap = cv2.VideoCapture(video)
    success,image = vidcap.read()
    count = 0
    
    while success:
      cv2.imwrite(path.join(outFolder,"frame%d."+ext) % count, image)     # save frame as JPEG file      
      success,image = vidcap.read()
      print('Read a new frame: ', success)
      count += 1
    os.chdir(outFolder)
    cmd = ["mm3d", "SetExif", "F35="+foc35, "F="+foc, "Cam="+cam]
    
    ret = call(cmd)
    
    if ret !=0:
        print('A micmac error has occured - check the micmac error log')
        sys.exit()
    
      
def num_subset(inFolder, outFolder, num=5, ext="JPG"):
    
    """ 
    Pick a subset of images from a video such as every fifth image (frame)
    
    This assumes you have used ffmpeg or a similar application to extract the frames first
    
    
    Parameters 
    ----------- 
    
    inFolder : string
              the folder with the images in 
        
    outFolder : string
           the folder the output images will go
        
    num : int 
              the subdivision - e.g. every fifth image

    ext : string
                 image extention e.g JPG, tif
        

    """
    # ffmpeg cmd just in case I end up[ doing anything like this]
    # ffmpeg -i *.mp4 Im_0000_%5d_Ok.png
    
    fileList = glob2.glob(os.path.join(inFolder, "*."+ext))
        
    
    
#    files = [os.path.split(file)[1] for file in fileList]
#    files.sort()
    
    ootList = []
    
    for f in range(0, len(fileList), num):
        ootList.append(fileList[f])
        
        
    
    Parallel(n_jobs=-1,verbose=5)(delayed(copy)(fl, 
            outFolder) for fl in ootList)


def rmse_vector_lyr(inShape, attributes):

    """ 
    Using sklearn get the rmse of 2 vector attributes 
    (the actual and predicted of course in the order ['actual', 'pred'])
    
    
    Parameters 
    ----------- 
    
    inShape : string
              the input vector of OGR type
        
    attributes : list
           a list of strings denoting the attributes
         

    """    
    
    #open the layer etc
    shp = ogr.Open(inShape)
    lyr = shp.GetLayer()
    labels = np.arange(lyr.GetFeatureCount())
    
    # empty arrays for att
    pred = np.zeros((1, lyr.GetFeatureCount()))
    true = np.zeros((1, lyr.GetFeatureCount()))
    
    for label in labels: 
        feat = lyr.GetFeature(label)
        true[:,label] = feat.GetField(attributes[0])
        pred[:,label] = feat.GetField(attributes[1])
    
    
    
    error = np.sqrt(metrics.mean_squared_error(true, pred))
    
    return error
    
        
def hist_match(inputImage, templateImage):
    
    
    
    # TODO optimise with either cython or numba
    
    """
    Adjust the pixel values of an image such that its histogram
    matches that of a target image. 
    
    Writes to the inputImage dataset so that it matches
    
    Notes: 
    -----------
        
    As the entire band histogram is required this can become memory
    intensive with very big images
    
    Inspire by/adapted from something on stack on image processing - credit to
    that author

    Parameters
    -----------
    
    inputImage : string
                 image to transform; the histogram is computed over the flattened array
            
    templateImage : string
                    template image can have different dimensions to source    
    
    """
    # TODO - cythinis or numba this one
    
    imgSource = Image.open(inputImage)
    
    sArr = np.array(imgSource)
        
    imgTemp = Image.open(templateImage)
    
    tArr = np.array(imgTemp)
    
    # "sArr" is a height x width x 3 numpy array

    
    #outArrs = []
    
    for band in tqdm(range(0, 3)):
        #print(band)
        # seems to be issue with combining properties as with templateRas hence
        # separate lines
        source = np.asarray(sArr[:,:, band])
        
        oldshape = source.shape
        
        template = np.asarray(tArr[:,:, band])
        
        
        #source = source.ravel()
        #template = template.ravel()
                
        
        # get the set of unique pixel values and their corresponding indices and
        # counts
        s_values, bin_idx, s_counts = np.unique(source.ravel(), return_inverse=True,
                                                return_counts=True)
        t_values, t_counts = np.unique(template.ravel(), return_counts=True)
    
        # take the cumsum of the counts and normalize by the number of pixels to
        # get the empirical cumulative distribution functions for the source and
        # template images (maps pixel value --> quantile)
        s_quantiles = np.cumsum(s_counts).astype(np.float64)
        s_quantiles /= s_quantiles[-1]
        t_quantiles = np.cumsum(t_counts).astype(np.float64)
        t_quantiles /= t_quantiles[-1]
    
        # interpolate linearly to find the pixel values in the template image
        # that correspond most closely to the quantiles in the source image
        interp_t_values = np.interp(s_quantiles, t_quantiles, t_values)
    
        out_array = interp_t_values[bin_idx].reshape(oldshape)
        
        # reuse the var from earlier
        sArr[:,:, band] = out_array
        
    # This seems rather ugly - but going on the docs   
    imOut = Image.fromarray(np.uint8(sArr))
    
    imOut.save(inputImage)

    
def array2raster(array, bands, inRaster, outRas, dtype, FMT=None):
    
    """
    Save a raster from a numpy array using the geoinfo from another.
    
    Parameters
    ----------      
    array : np array
            a numpy array.
    
    bands : int
            the no of bands. 
    
    inRaster : string
               the path of a raster.
    
    outRas : string
             the path of the output raster.
    
    dtype : int 
            though you need to know what the number represents!
            a GDAL datatype (see the GDAL website) e.g gdal.GDT_Int32
    
    FMT  : string 
           (optional) a GDAL raster format (see the GDAL website) eg Gtiff, HFA, KEA.
        
    
    """

    if FMT == None:
        FMT = 'Gtiff'
        
    if FMT == 'HFA':
        fmt = '.img'
    if FMT == 'KEA':
        fmt = '.kea'
    if FMT == 'Gtiff':
        fmt = '.tif'    
    
    inras = gdal.Open(inRaster, gdal.GA_ReadOnly)    
    
    x_pixels = inras.RasterXSize  # number of pixels in x
    y_pixels = inras.RasterYSize  # number of pixels in y
    geotransform = inras.GetGeoTransform()
    PIXEL_SIZE = geotransform[1]  # size of the pixel...they are square so thats ok.
    #if not would need w x h
    x_min = geotransform[0]
    y_max = geotransform[3]
    # x_min & y_max are like the "top left" corner.
    projection = inras.GetProjection()
    geotransform = inras.GetGeoTransform()   

    driver = gdal.GetDriverByName(FMT)

    dataset = driver.Create(
        outRas, 
        x_pixels,
        y_pixels,
        bands,
        dtype)

    dataset.SetGeoTransform((
        x_min,    # 0
        PIXEL_SIZE,  # 1
        0,                      # 2
        y_max,    # 3
        0,                      # 4
        -PIXEL_SIZE))    

    dataset.SetProjection(projection)
    if bands == 1:
        dataset.GetRasterBand(1).WriteArray(array)
        dataset.FlushCache()  # Write to disk.
        dataset=None
        #print('Raster written to disk')
    else:
    # Here we loop through bands
        for band in range(1,bands+1):
            Arr = array[:,:,band-1]
            dataset.GetRasterBand(band).WriteArray(Arr)
        dataset.FlushCache()  # Write to disk.
        dataset=None
        #print('Raster w


       
